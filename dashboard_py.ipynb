{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/1tg9J2XuzGRk6Lj5uT+S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nurin1732/XenberSDU/blob/frontend/dashboard_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktWX29RJ1o2t"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import streamlit as st\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "API_BASE_URL = os.getenv(\"API_BASE_URL\", \"http://localhost:8000\")\n",
        "REFRESH_MS = int(os.getenv(\"REFRESH_MS\", \"5000\"))\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"Enterprise Ops Analytics\",\n",
        "    page_icon=\"ðŸ“Š\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\",\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Utilities\n",
        "# -----------------------------\n",
        "def api_get(path, params=None, timeout=5):\n",
        "    \"\"\"\n",
        "    Safe GET wrapper that falls back to mock data when API is unavailable.\n",
        "    Returns (data, error). data is dict/list, error is None or str.\n",
        "    \"\"\"\n",
        "    url = f\"{API_BASE_URL}{path}\"\n",
        "    try:\n",
        "        resp = requests.get(url, params=params, timeout=timeout)\n",
        "        resp.raise_for_status()\n",
        "        return resp.json(), None\n",
        "    except Exception as e:\n",
        "        return None, str(e)\n",
        "\n",
        "def as_timeseries_df(series_dict, date_key=\"timestamp\", value_key=\"value\"):\n",
        "    \"\"\"\n",
        "    Convert API/Mock dict list to pandas DataFrame sorted by timestamp.\n",
        "    Expects list of {timestamp: ISO8601, value: float}.\n",
        "    \"\"\"\n",
        "    if isinstance(series_dict, list):\n",
        "        df = pd.DataFrame(series_dict)\n",
        "    else:\n",
        "        df = pd.DataFrame(series_dict or [])\n",
        "    if date_key in df.columns:\n",
        "        df[date_key] = pd.to_datetime(df[date_key], errors=\"coerce\")\n",
        "        df = df.sort_values(date_key)\n",
        "        df = df.reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "def card_metric(label, value, delta=None, help_text=None):\n",
        "    \"\"\"\n",
        "    Render a simple metric card.\n",
        "    \"\"\"\n",
        "    st.metric(label, value, delta=delta)\n",
        "    if help_text:\n",
        "        st.caption(help_text)\n",
        "\n",
        "# -----------------------------\n",
        "# Mock data generators (used until backend API is ready)\n",
        "# -----------------------------\n",
        "def mock_forecast(n_points=48, start=None):\n",
        "    start = start or datetime.now() - timedelta(hours=n_points)\n",
        "    base = 100\n",
        "    timestamps = [start + timedelta(hours=i) for i in range(n_points)]\n",
        "    values = base + np.linspace(-5, 15, n_points) + np.random.normal(0, 3, n_points)\n",
        "    return [{\"timestamp\": t.isoformat(), \"value\": float(v)} for t, v in zip(timestamps, values)]\n",
        "\n",
        "def mock_anomalies(n_points=48, anomaly_ratio=0.1):\n",
        "    series = mock_forecast(n_points)\n",
        "    df = pd.DataFrame(series)\n",
        "    anomalies_idx = np.random.choice(range(n_points), max(1, int(n_points * anomaly_ratio)), replace=False)\n",
        "    rows = []\n",
        "    for i in anomalies_idx:\n",
        "        rows.append({\n",
        "            \"timestamp\": df.iloc[i][\"timestamp\"],\n",
        "            \"severity\": float(np.random.uniform(0.5, 1.0)),\n",
        "            \"metric\": \"demand\",\n",
        "            \"value\": float(df.iloc[i][\"value\"]),\n",
        "            \"reason\": \"Deviation from expected pattern\",\n",
        "        })\n",
        "    return rows\n",
        "\n",
        "def mock_optimization(n_items=5):\n",
        "    items = []\n",
        "    for i in range(n_items):\n",
        "        items.append({\n",
        "            \"id\": f\"OP-{100+i}\",\n",
        "            \"category\": np.random.choice([\"Staffing\", \"Inventory\", \"Maintenance\"]),\n",
        "            \"recommendation\": np.random.choice([\n",
        "                \"Shift 2 adds 1 headcount\",\n",
        "                \"Reorder SKU-12 by 150 units\",\n",
        "                \"Advance maintenance of Line-B\",\n",
        "                \"Delay purchase till next week\",\n",
        "            ]),\n",
        "            \"expected_impact\": f\"{np.random.randint(3,15)}% cost reduction\",\n",
        "            \"priority\": np.random.choice([\"High\", \"Medium\", \"Low\"]),\n",
        "            \"eta\": (datetime.now() + timedelta(days=np.random.randint(1,7))).date().isoformat(),\n",
        "        })\n",
        "    return items\n",
        "\n",
        "def mock_alerts(n=4):\n",
        "    levels = [\"Info\", \"Warning\", \"Critical\"]\n",
        "    alerts = []\n",
        "    for i in range(n):\n",
        "        alerts.append({\n",
        "            \"id\": f\"AL-{1000+i}\",\n",
        "            \"level\": np.random.choice(levels, p=[0.5, 0.35, 0.15]),\n",
        "            \"title\": np.random.choice([\n",
        "                \"Unexpected demand spike\",\n",
        "                \"Sensor dropouts detected\",\n",
        "                \"Stockout risk in Warehouse A\",\n",
        "                \"Processing queue backlog\",\n",
        "            ]),\n",
        "            \"detail\": np.random.choice([\n",
        "                \"Investigate line throughput variance.\",\n",
        "                \"Check network for device connectivity.\",\n",
        "                \"Expedite purchase order for SKU-27.\",\n",
        "                \"Scale workers on shift 1 temporarily.\",\n",
        "            ]),\n",
        "            \"created_at\": datetime.now().isoformat(),\n",
        "        })\n",
        "    return alerts\n",
        "\n",
        "# -----------------------------\n",
        "# Sidebar\n",
        "# -----------------------------\n",
        "with st.sidebar:\n",
        "    st.title(\"Controls\")\n",
        "    st.text_input(\"API base URL\", API_BASE_URL, key=\"api_base_url\")\n",
        "    st.checkbox(\"Use auto-refresh\", value=True, key=\"auto_refresh\")\n",
        "    st.number_input(\"Refresh interval (ms)\", min_value=1000, max_value=60000, value=REFRESH_MS, step=1000, key=\"refresh_ms\")\n",
        "\n",
        "    st.divider()\n",
        "    st.caption(\"Demo filters\")\n",
        "    period = st.selectbox(\"Forecast period\", [\"24h\", \"48h\", \"7d\"], index=1)\n",
        "    anomaly_threshold = st.slider(\"Anomaly severity threshold\", 0.0, 1.0, 0.6, 0.05)\n",
        "\n",
        "# Update config live\n",
        "API_BASE_URL = st.session_state.get(\"api_base_url\", API_BASE_URL)\n",
        "REFRESH_MS = int(st.session_state.get(\"refresh_ms\", REFRESH_MS))\n",
        "\n",
        "if st.session_state.get(\"auto_refresh\", True):\n",
        "    st.experimental_singleton.clear() if False else None  # placeholder, avoids warning; harmless\n",
        "    st_autorefresh = st.experimental_rerun if False else None  # placeholder\n",
        "    st.experimental_set_query_params(ts=str(int(time.time()*1000)))  # lightweight cache-bust\n",
        "    st.experimental_data_editor if False else None  # noop\n",
        "    st.experimental_show if False else None  # noop\n",
        "    st.experimental_get_query_params()\n",
        "    st_autorefresh_component = st.empty()\n",
        "    st_autorefresh_component = st.autorefresh(interval=REFRESH_MS, key=\"refresh\")\n",
        "\n",
        "# -----------------------------\n",
        "# Header\n",
        "# -----------------------------\n",
        "st.title(\"ðŸ“Š Intelligent Predictive Analytics for Enterprise Operations\")\n",
        "st.caption(\"Forecast KPIs, detect anomalies, and recommend optimizations with actionable alerts.\")\n",
        "\n",
        "# -----------------------------\n",
        "# Tabs\n",
        "# -----------------------------\n",
        "tab_home, tab_forecast, tab_anomaly, tab_opt, tab_alerts = st.tabs(\n",
        "    [\"Home\", \"Forecasting\", \"Anomaly Detection\", \"Optimization\", \"Alerts\"]\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Home\n",
        "# -----------------------------\n",
        "with tab_home:\n",
        "    col1, col2, col3, col4 = st.columns(4)\n",
        "    # Pull a quick sample from APIs (with fallback)\n",
        "    fc_data, fc_err = api_get(\"/forecast\", params={\"period\": period})\n",
        "    an_data, an_err = api_get(\"/anomalies\", params={\"threshold\": anomaly_threshold})\n",
        "    op_data, op_err = api_get(\"/optimize\")\n",
        "    al_data, al_err = api_get(\"/alerts\")\n",
        "\n",
        "    if fc_err: fc_data = mock_forecast(n_points=24 if period==\"24h\" else 48 if period==\"48h\" else 7*24)\n",
        "    if an_err: an_data = mock_anomalies(n_points=48, anomaly_ratio=0.12)\n",
        "    if op_err: op_data = mock_optimization(n_items=5)\n",
        "    if al_err: al_data = mock_alerts(n=4)\n",
        "\n",
        "    df_fc = as_timeseries_df(fc_data)\n",
        "    last_val = df_fc[\"value\"].iloc[-1] if not df_fc.empty else np.nan\n",
        "    prev_val = df_fc[\"value\"].iloc[-2] if len(df_fc) > 1 else np.nan\n",
        "    delta = None if (np.isnan(last_val) or np.isnan(prev_val)) else round(last_val - prev_val, 2)\n",
        "\n",
        "    with col1: card_metric(\"Latest KPI\", f\"{round(last_val, 2)}\", delta, \"From Forecast\")\n",
        "    with col2: card_metric(\"Anomalies (last 48h)\", f\"{len(an_data)}\")\n",
        "    with col3: card_metric(\"Recommendations\", f\"{len(op_data)}\")\n",
        "    with col4: card_metric(\"Active Alerts\", f\"{len(al_data)}\")\n",
        "\n",
        "    st.divider()\n",
        "    st.subheader(\"Overview chart\")\n",
        "    if not df_fc.empty:\n",
        "        st.line_chart(df_fc.set_index(\"timestamp\")[\"value\"], height=250, use_container_width=True)\n",
        "    else:\n",
        "        st.info(\"No forecast data available yet.\")\n",
        "\n",
        "# -----------------------------\n",
        "# Forecasting\n",
        "# -----------------------------\n",
        "with tab_forecast:\n",
        "    st.subheader(\"Forecasted KPI\")\n",
        "    fc_data, err = api_get(\"/forecast\", params={\"period\": period})\n",
        "    if err:\n",
        "        st.warning(\"API unavailable, showing mock forecast.\")\n",
        "        fc_data = mock_forecast(n_points=24 if period==\"24h\" else 48 if period==\"48h\" else 7*24)\n",
        "\n",
        "    df = as_timeseries_df(fc_data)\n",
        "    if df.empty:\n",
        "        st.info(\"No forecast data.\")\n",
        "    else:\n",
        "        left, right = st.columns([3, 2])\n",
        "        with left:\n",
        "            st.line_chart(df.set_index(\"timestamp\")[\"value\"], height=350, use_container_width=True)\n",
        "        with right:\n",
        "            st.write(\"Summary\")\n",
        "            st.write({\n",
        "                \"min\": float(df[\"value\"].min()),\n",
        "                \"max\": float(df[\"value\"].max()),\n",
        "                \"mean\": float(df[\"value\"].mean()),\n",
        "                \"std\": float(df[\"value\"].std()),\n",
        "            })\n",
        "            st.caption(\"Trend and dispersion help estimate operational stability.\")\n",
        "\n",
        "        st.divider()\n",
        "        st.download_button(\n",
        "            label=\"Download forecast (CSV)\",\n",
        "            data=df.to_csv(index=False).encode(\"utf-8\"),\n",
        "            file_name=f\"forecast_{period}.csv\",\n",
        "            mime=\"text/csv\",\n",
        "        )\n",
        "\n",
        "# -----------------------------\n",
        "# Anomaly Detection\n",
        "# -----------------------------\n",
        "with tab_anomaly:\n",
        "    st.subheader(\"Detected anomalies\")\n",
        "    an_data, err = api_get(\"/anomalies\", params={\"threshold\": anomaly_threshold})\n",
        "    if err:\n",
        "        st.warning(\"API unavailable, showing mock anomalies.\")\n",
        "        an_data = mock_anomalies(n_points=48, anomaly_ratio=0.12)\n",
        "\n",
        "    df = pd.DataFrame(an_data)\n",
        "    if df.empty:\n",
        "        st.info(\"No anomalies detected.\")\n",
        "    else:\n",
        "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
        "        df = df.sort_values(\"timestamp\")\n",
        "        # Scatter plot with severity as color\n",
        "        st.scatter_chart(\n",
        "            df.rename(columns={\"timestamp\": \"index\"}).set_index(\"index\")[[\"severity\"]],\n",
        "            height=350,\n",
        "            use_container_width=True,\n",
        "        )\n",
        "        st.caption(\"Bubble intensity indicates severity. Use threshold to focus ops response.\")\n",
        "        st.divider()\n",
        "        st.dataframe(\n",
        "            df[[\"timestamp\", \"metric\", \"value\", \"severity\", \"reason\"]],\n",
        "            use_container_width=True,\n",
        "            height=300,\n",
        "        )\n",
        "\n",
        "# -----------------------------\n",
        "# Optimization\n",
        "# -----------------------------\n",
        "with tab_opt:\n",
        "    st.subheader(\"Optimization recommendations\")\n",
        "    op_data, err = api_get(\"/optimize\")\n",
        "    if err:\n",
        "        st.warning(\"API unavailable, showing mock recommendations.\")\n",
        "        op_data = mock_optimization(n_items=7)\n",
        "\n",
        "    df = pd.DataFrame(op_data)\n",
        "    if df.empty:\n",
        "        st.info(\"No optimization output.\")\n",
        "    else:\n",
        "        # Priority filter\n",
        "        priority = st.multiselect(\"Filter by priority\", [\"High\", \"Medium\", \"Low\"], default=[\"High\", \"Medium\", \"Low\"])\n",
        "        df_f = df[df[\"priority\"].isin(priority)]\n",
        "        st.dataframe(df_f, use_container_width=True, height=350)\n",
        "\n",
        "        st.divider()\n",
        "        st.download_button(\n",
        "            label=\"Download recommendations (CSV)\",\n",
        "            data=df_f.to_csv(index=False).encode(\"utf-8\"),\n",
        "            file_name=\"optimization_recommendations.csv\",\n",
        "            mime=\"text/csv\",\n",
        "        )\n",
        "\n",
        "# -----------------------------\n",
        "# Alerts\n",
        "# -----------------------------\n",
        "with tab_alerts:\n",
        "    st.subheader(\"Alerts panel\")\n",
        "    al_data, err = api_get(\"/alerts\")\n",
        "    if err:\n",
        "        st.warning(\"API unavailable, showing mock alerts.\")\n",
        "        al_data = mock_alerts(n=6)\n",
        "\n",
        "    # Sort by level then created_at\n",
        "    level_order = {\"Critical\": 0, \"Warning\": 1, \"Info\": 2}\n",
        "    al_df = pd.DataFrame(al_data)\n",
        "    if al_df.empty:\n",
        "        st.info(\"No active alerts.\")\n",
        "    else:\n",
        "        al_df[\"sort_level\"] = al_df[\"level\"].map(level_order).fillna(9)\n",
        "        al_df[\"created_at\"] = pd.to_datetime(al_df[\"created_at\"], errors=\"coerce\")\n",
        "        al_df = al_df.sort_values([\"sort_level\", \"created_at\"])\n",
        "\n",
        "        for _, row in al_df.iterrows():\n",
        "            level = row.get(\"level\", \"Info\")\n",
        "            color = \"red\" if level == \"Critical\" else \"orange\" if level == \"Warning\" else \"blue\"\n",
        "            with st.container(border=True):\n",
        "                st.markdown(f\"**[{level}]** {row.get('title', '')}\")\n",
        "                st.caption(f\"ID: {row.get('id','')} â€¢ {row.get('created_at','')}\")\n",
        "                st.write(row.get(\"detail\", \"\"))\n",
        "                st.progress(0.9 if level == \"Critical\" else 0.6 if level == \"Warning\" else 0.3, text=f\"{level} level\")\n",
        "\n",
        "        st.divider()\n",
        "        st.download_button(\n",
        "            label=\"Export alerts (JSON)\",\n",
        "            data=json.dumps(al_data, indent=2).encode(\"utf-8\"),\n",
        "            file_name=\"alerts.json\",\n",
        "            mime=\"application/json\",\n",
        "        )\n",
        "\n",
        "# -----------------------------\n",
        "# Footer\n",
        "# -----------------------------\n",
        "st.caption(\"Powered by JamAI-based backend (RAG + multi-step), visualized in Streamlit. BM/EN supported in responses.\")"
      ]
    }
  ]
}